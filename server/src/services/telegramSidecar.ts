/**
 * Telegram Sidecar â€” Sovereign Bridge to the Cortex
 *
 * Runs alongside the Express backend as a Telegram bot. Filters by
 * a single USER_ID (sovereign mode â€” only the owner can interact).
 *
 * Capabilities:
 *   - Text messages â†’ cortexRouter.routeSignal (channel: 'telegram')
 *   - Voice notes (.ogg) â†’ Whisper transcription â†’ routeSignal
 *   - Inline keyboard for draft confirmation/rejection â†’ recordHandshake
 *   - Auto-commit feedback with summary
 */

import { Telegraf, type Context } from 'telegraf'
import type { Update, Message } from 'telegraf/types'
import OpenAI, { toFile } from 'openai'
import { env } from '../config.js'
import { cortexRouter } from './cortex/cortexRouter.js'
import type { CortexRouteResult, HandshakeStatus } from './cortex/types.js'

// â”€â”€ OpenAI client for Whisper transcription â”€â”€
const openai = new OpenAI({ apiKey: env.openaiKey })

// â”€â”€ Sovereign gate: only this user can interact â”€â”€
const OWNER_ID = env.telegramUserId ? Number(env.telegramUserId) : 0

function isOwner(ctx: Context): boolean {
    return ctx.from?.id === OWNER_ID
}

// â”€â”€ Helpers â”€â”€

function truncate(text: string, max = 120): string {
    return text.length > max ? text.slice(0, max) + 'â€¦' : text
}

function formatDecisionMessage(result: CortexRouteResult, originalText: string): string {
    const isAutoCommit = result.reason?.some((r) => r.includes('auto_commit=true'))

    if (isAutoCommit) {
        const summary = result.financeDraft
            ? `${result.financeDraft.merchant} â€¢ ${result.financeDraft.amount} ${result.financeDraft.currency}`
            : truncate(originalText, 60)
        return `âœ… *Auto-executado*\n\nğŸ“¦ MÃ³dulo: \`${result.route}\`\nğŸ“ ${summary}\nğŸ¯ ConfianÃ§a: ${(result.confidence * 100).toFixed(0)}%`
    }

    if (result.nextAction === 'query_openai_with_context') {
        return 'ğŸ’¬ Processando resposta...'
    }

    if (result.nextAction?.startsWith('ambient_')) {
        const draft = result.financeDraft ?? result.moduleDraft ?? {}
        const draftLines = Object.entries(draft)
            .filter(([, v]) => v != null && v !== '')
            .map(([k, v]) => `  ${k}: \`${v}\``)
            .join('\n')
        return `ğŸ’¡ *Draft criado*\n\nğŸ“¦ MÃ³dulo: \`${result.route}\`\n${draftLines}`
    }

    return `âš™ï¸ Processado â†’ \`${result.route}\` (${result.nextAction})`
}

// â”€â”€ Build inline keyboard for draft confirmation â”€â”€
function buildDraftKeyboard(rawSignalId: string, module: string) {
    return {
        inline_keyboard: [
            [
                { text: 'âœ… Confirmar', callback_data: `confirm:${rawSignalId}:${module}` },
                { text: 'âŒ Rejeitar', callback_data: `reject:${rawSignalId}:${module}` },
            ],
        ],
    }
}

// â”€â”€ Transcribe voice note via Whisper â”€â”€
async function transcribeVoiceNote(fileBuffer: Buffer, filename: string): Promise<string> {
    const transcription = await openai.audio.transcriptions.create({
        file: await toFile(fileBuffer, filename, { type: 'audio/ogg' }),
        model: 'whisper-1',
        language: 'pt',
        response_format: 'text',
        temperature: 0,
    })
    return (transcription as unknown as string).trim()
}

// â”€â”€ Route text through Cortex â”€â”€
async function routeTextToCortex(
    text: string,
    signalType: 'text' | 'voice',
): Promise<CortexRouteResult> {
    return cortexRouter.routeSignal({
        signalType,
        rawText: text,
        channel: 'telegram',
    })
}

// â”€â”€ Handle cortex response + optional chat reply â”€â”€
async function handleCortexResult(
    ctx: Context,
    result: CortexRouteResult,
    originalText: string,
): Promise<void> {
    const isAutoCommit = result.reason?.some((r) => r.includes('auto_commit=true'))

    if (isAutoCommit) {
        await ctx.replyWithMarkdownV2(escapeMarkdownV2(formatDecisionMessage(result, originalText)))
        return
    }

    if (result.nextAction === 'query_openai_with_context') {
        // Get a chat reply from cortex
        try {
            const chatResult = await openai.chat.completions.create({
                model: 'gpt-4o-mini',
                messages: [
                    {
                        role: 'system',
                        content: `Eres Buggy, un asistente financiero conciso. Contexto:\n${result.contextMarkdown ?? ''}`,
                    },
                    { role: 'user', content: originalText },
                ],
                temperature: 0.4,
                max_tokens: 400,
            })
            const reply = chatResult.choices[0]?.message?.content || 'Sem resposta.'
            await ctx.reply(reply)
        } catch {
            await ctx.reply('âŒ Erro ao processar resposta do chat.')
        }
        return
    }

    if (result.nextAction?.startsWith('ambient_')) {
        await ctx.reply(formatDecisionMessage(result, originalText), {
            parse_mode: 'Markdown',
            reply_markup: buildDraftKeyboard(result.rawSignalId, result.route),
        })
        return
    }

    await ctx.reply(formatDecisionMessage(result, originalText), { parse_mode: 'Markdown' })
}

// Escape special chars for MarkdownV2
function escapeMarkdownV2(text: string): string {
    return text.replace(/([_*\[\]()~`>#+\-=|{}.!\\])/g, '\\$1')
}

// â”€â”€ Create and configure the bot â”€â”€
export function createTelegramSidecar(): Telegraf | null {
    if (!env.telegramBotToken) {
        console.log('[telegram] No TELEGRAM_BOT_TOKEN set â€” sidecar disabled.')
        return null
    }

    if (!OWNER_ID) {
        console.log('[telegram] No TELEGRAM_USER_ID set â€” sidecar disabled.')
        return null
    }

    const bot = new Telegraf(env.telegramBotToken)

    // â”€â”€ Sovereign gate middleware â”€â”€
    bot.use((ctx, next) => {
        if (!isOwner(ctx)) {
            // Silently drop non-owner messages
            return
        }
        return next()
    })

    // â”€â”€ /start command â”€â”€
    bot.start((ctx) => {
        ctx.reply(
            'ğŸ› *Buggy Telegram Sidecar*\n\n' +
            'Estou ligado ao teu Cortex local.\n' +
            'Envia texto ou notas de voz.\n\n' +
            '`/gastos 50 EUR almoÃ§o`\n' +
            '`/todo comprar leite`',
            { parse_mode: 'Markdown' },
        )
    })

    // â”€â”€ Text messages â”€â”€
    bot.on('text', async (ctx) => {
        const text = ctx.message.text.trim()
        if (!text || text.startsWith('/start')) return

        try {
            await ctx.sendChatAction('typing')
            const result = await routeTextToCortex(text, 'text')
            await handleCortexResult(ctx, result, text)
        } catch (err) {
            console.error('[telegram] text route error:', err)
            await ctx.reply('âŒ Erro na ligaÃ§Ã£o ao Cortex.')
        }
    })

    // â”€â”€ Voice notes â”€â”€
    bot.on('voice', async (ctx) => {
        try {
            await ctx.sendChatAction('typing')

            // Download the voice file from Telegram
            const fileId = ctx.message.voice.file_id
            const fileLink = await ctx.telegram.getFileLink(fileId)
            const response = await fetch(fileLink.href)
            const arrayBuffer = await response.arrayBuffer()
            const fileBuffer = Buffer.from(arrayBuffer)

            // Transcribe via Whisper
            const transcript = await transcribeVoiceNote(fileBuffer, `voice_${fileId}.ogg`)

            if (!transcript) {
                await ctx.reply('ğŸ”‡ NÃ£o consegui transcrever a nota de voz.')
                return
            }

            await ctx.reply(`ğŸ¤ _${truncate(transcript, 200)}_`, { parse_mode: 'Markdown' })

            // Route the transcription through Cortex
            const result = await routeTextToCortex(transcript, 'voice')
            await handleCortexResult(ctx, result, transcript)
        } catch (err) {
            console.error('[telegram] voice route error:', err)
            await ctx.reply('âŒ Erro ao processar nota de voz.')
        }
    })

    // â”€â”€ Inline keyboard callbacks (draft confirm/reject) â”€â”€
    bot.on('callback_query', async (ctx) => {
        const data = 'data' in ctx.callbackQuery ? ctx.callbackQuery.data : undefined
        if (!data) return

        const [action, rawSignalId, module] = data.split(':')
        if (!rawSignalId || !module) {
            await ctx.answerCbQuery('Dados invÃ¡lidos.')
            return
        }

        const status: HandshakeStatus = action === 'confirm' ? 'approved' : 'rejected'

        try {
            await cortexRouter.recordHandshake({
                rawSignalId,
                module: module as any,
                status,
                confidence: status === 'approved' ? 1.0 : null,
                payload: {},
            })

            const emoji = status === 'approved' ? 'âœ…' : 'âŒ'
            const label = status === 'approved' ? 'Confirmado' : 'Rejeitado'
            await ctx.editMessageText(`${emoji} ${label} â€” \`${module}\``, { parse_mode: 'Markdown' })
            await ctx.answerCbQuery(label)
        } catch (err) {
            console.error('[telegram] handshake error:', err)
            await ctx.answerCbQuery('Erro ao processar.')
        }
    })

    return bot
}

// â”€â”€ Launch (with graceful shutdown) â”€â”€
export async function startTelegramSidecar(): Promise<void> {
    const bot = createTelegramSidecar()
    if (!bot) return

    // Graceful shutdown
    const stopSignals: NodeJS.Signals[] = ['SIGINT', 'SIGTERM']
    for (const signal of stopSignals) {
        process.once(signal, () => {
            console.log(`[telegram] Received ${signal}, stopping bot...`)
            bot.stop(signal)
        })
    }

    try {
        await bot.launch()
        console.log(`[telegram] ğŸ› Buggy Sidecar online â€” sovereign mode (user: ${OWNER_ID})`)
    } catch (err) {
        console.error('[telegram] Failed to start bot:', err)
    }
}
